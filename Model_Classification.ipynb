{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = tf.config.experimental.list_physical_devices('GPU')\n",
    "gpu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('House_Room_Dataset', label_mode='categorical',image_size=(224, 224))\n",
    "data_iterator = data.as_numpy_iterator()\n",
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y: (x/255, y))\n",
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.7)\n",
    "val_size = int(len(data)*.2)+1\n",
    "test_size = int(len(data)*.1)+1\n",
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFont\n",
    "font = ImageFont.truetype(\"arial.ttf\", 32)\n",
    "\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Conv2D(16,(3,3), 1, activation='relu', input_shape=(224,224,3)))\n",
    "model1.add(MaxPooling2D())\n",
    "model1.add(Dropout(0.5))\n",
    "\n",
    "model1.add(Conv2D(32,(3,3), 1, activation='relu'))\n",
    "model1.add(MaxPooling2D())\n",
    "model1.add(Dropout(0.5))\n",
    "\n",
    "model1.add(Conv2D(16,(3,3), 1, activation='relu'))\n",
    "model1.add(MaxPooling2D())\n",
    "model1.add(Dropout(0.5))\n",
    "\n",
    "model1.add(Flatten())\n",
    "\n",
    "model1.add(Dense(128,activation='relu'))\n",
    "model1.add(Dense(5,activation='softmax'))\n",
    "\n",
    "import visualkeras\n",
    "\n",
    "visualkeras.layered_view(model1).show() # display using your system viewer\n",
    "visualkeras.layered_view(model1, legend=True, font=font, scale_xy=1, scale_z=1, max_z=1000, to_file='output.png') # write to disk\n",
    "visualkeras.layered_view(model1, legend=True, font=font, scale_xy=1, scale_z=1, max_z=1000, to_file='output.png').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile('adam', loss=tf.losses.CategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "hist1 = model1.fit(train, epochs= 30, validation_data=val, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist1.history['loss'], color='teal', label='Training loss')\n",
    "plt.plot(hist1.history['val_loss'], color='orange', label='Validation loss')\n",
    "fig.suptitle('Model Loss Values', fontsize=20)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Epoches')\n",
    "plt.ylabel('Losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist1.history['accuracy'], color='teal', label='Train Accuracy')\n",
    "plt.plot(hist1.history['val_accuracy'], color='orange', label='Validation Accuracy')\n",
    "fig.suptitle('Model Accuracy Values', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save(os.path.join('models','Model-Classification.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model(os.path.join('models', 'Model-Classification.h5'))\n",
    "print(new_model)\n",
    "\n",
    "conf_mat = tf.zeros((5, 5), dtype=tf.int32)\n",
    "\n",
    "for batch in test.as_numpy_iterator():\n",
    "    X, y = batch\n",
    "    yhat = new_model.predict(X)\n",
    "    y_pred = np.argmax(yhat, axis=1)\n",
    "    y_true = np.argmax(y, axis=1)\n",
    "    conf_mat += tf.math.confusion_matrix(y_true, y_pred, num_classes=5)\n",
    "\n",
    "class_names = ['Bathroom', 'Bedroom', 'Dining', 'Kitchen', 'Living Room']\n",
    "conf_mat_norm = np.around(conf_mat.numpy() / conf_mat.numpy().sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(conf_mat_norm, xticklabels=class_names, yticklabels=class_names, annot=True, fmt='.2f')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss1, test_acc1 = model1.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Bathroom', 'Bedroom', 'Dining', 'Kitchen', 'Living Room']\n",
    "\n",
    "img = cv2.imread('bed_test.jpg')\n",
    "resize = tf.image.resize(img, (224, 224))\n",
    "input_image = np.expand_dims(resize / 255, 0)\n",
    "yhat = model1.predict(input_image)\n",
    "predicted_class_index = np.argmax(yhat)\n",
    "labels = ['Bathroom', 'Bedroom', 'Dining', 'Kitchen', 'Living Room']\n",
    "predicted_label = labels[predicted_class_index]\n",
    "\n",
    "# Print the predicted label\n",
    "print(\"Predicted label: \", predicted_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('House_Room_Dataset', label_mode='categorical',image_size=(224, 224))\n",
    "data_iterator = data.as_numpy_iterator()\n",
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y: (x/255, y))\n",
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.7)\n",
    "val_size = int(len(data)*.2)+1\n",
    "test_size = int(len(data)*.1)+1\n",
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_vgg16 = VGG16(input_shape=(224, 224, 3), include_top=False)\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model_vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add new classification layers on top of the pre-trained model\n",
    "model2 = Sequential()\n",
    "model2.add(base_model_vgg16)\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile('adam', loss=tf.losses.CategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "hist2 = model2.fit(train, epochs= 30, validation_data=val, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist2.history['loss'], color='teal', label='Training loss')\n",
    "plt.plot(hist2.history['val_loss'], color='orange', label='Validation loss')\n",
    "fig.suptitle('VGG16 Loss Values', fontsize=20)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Epoches')\n",
    "plt.ylabel('Losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist2.history['accuracy'], color='teal', label='Train Accuracy')\n",
    "plt.plot(hist2.history['val_accuracy'], color='orange', label='Validation Accuracy')\n",
    "fig.suptitle('VGG16 Accuracy Values', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(os.path.join('models','VGG16-Classification.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss2, test_acc2 = model2.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = tf.zeros((5, 5), dtype=tf.int32)\n",
    "\n",
    "for batch in test.as_numpy_iterator():\n",
    "    X, y = batch\n",
    "    yhat = model2.predict(X)\n",
    "    y_pred = np.argmax(yhat, axis=1)\n",
    "    y_true = np.argmax(y, axis=1)\n",
    "    conf_mat += tf.math.confusion_matrix(y_true, y_pred, num_classes=5)\n",
    "\n",
    "class_names = ['Bathroom', 'Bedroom', 'Dining', 'Kitchen', 'Living Room']\n",
    "conf_mat_norm = np.around(conf_mat.numpy() / conf_mat.numpy().sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(conf_mat_norm, xticklabels=class_names, yticklabels=class_names, annot=True, fmt='.2f')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Bathroom', 'Bedroom', 'Dining', 'Kitchen', 'Living Room']\n",
    "\n",
    "img = cv2.imread('bath_test.jpg')\n",
    "resize = tf.image.resize(img, (224, 224))\n",
    "input_image = np.expand_dims(resize / 255, 0)\n",
    "yhat = model2.predict(input_image)\n",
    "predicted_class_index = np.argmax(yhat)\n",
    "labels = ['Bathroom', 'Bedroom', 'Dining', 'Kitchen', 'Living Room']\n",
    "predicted_label = labels[predicted_class_index]\n",
    "\n",
    "# Print the predicted label\n",
    "print(\"Predicted label: \", predicted_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('House_Room_Dataset', label_mode='categorical',image_size=(224, 224))\n",
    "data_iterator = data.as_numpy_iterator()\n",
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y: (x/255, y))\n",
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.7)\n",
    "val_size = int(len(data)*.2)+1\n",
    "test_size = int(len(data)*.1)+1\n",
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_vgg19 = VGG19(input_shape=(224, 224, 3), include_top=False)\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model_vgg19.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add new classification layers on top of the pre-trained model\n",
    "model3 = Sequential()\n",
    "model3.add(base_model_vgg19)\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile('adam', loss=tf.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "# Define the callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist3 = model3.fit(train, epochs= 30, validation_data=val, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist3.history['loss'], color='teal', label='Training loss')\n",
    "plt.plot(hist3.history['val_loss'], color='orange', label='Validation loss')\n",
    "fig.suptitle('VGG19 Loss Values', fontsize=20)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Epoches')\n",
    "plt.ylabel('Losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist3.history['accuracy'], color='teal', label='Train Accuracy')\n",
    "plt.plot(hist3.history['val_accuracy'], color='orange', label='Validation Accuracy')\n",
    "fig.suptitle('VGG19 Accuracy Values', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = tf.zeros((5, 5), dtype=tf.int32)\n",
    "\n",
    "for batch in test.as_numpy_iterator():\n",
    "    X, y = batch\n",
    "    yhat = model3.predict(X)\n",
    "    y_pred = np.argmax(yhat, axis=1)\n",
    "    y_true = np.argmax(y, axis=1)\n",
    "    conf_mat += tf.math.confusion_matrix(y_true, y_pred, num_classes=5)\n",
    "\n",
    "class_names = ['Bathroom', 'Bedroom', 'Dining', 'Kitchen', 'Living Room']\n",
    "conf_mat_norm = np.around(conf_mat.numpy() / conf_mat.numpy().sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(conf_mat_norm, xticklabels=class_names, yticklabels=class_names, annot=True, fmt='.2f')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save(os.path.join('models','VGG19-Classification.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss3, test_acc3 = model3.evaluate(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Inception-V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('House_Room_Dataset', label_mode='categorical',image_size=(299, 299))\n",
    "data_iterator = data.as_numpy_iterator()\n",
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y: (x/255, y))\n",
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.7)\n",
    "val_size = int(len(data)*.2)+1\n",
    "test_size = int(len(data)*.1)+1\n",
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_inception = InceptionV3(input_shape=(299, 299, 3), include_top=False)\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model_inception.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add new classification layers on top of the pre-trained model\n",
    "model4 = Sequential()\n",
    "model4.add(base_model_inception)\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(128, activation='relu'))\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile('adam', loss=tf.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "# Define the callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist4 = model4.fit(train, epochs= 30, validation_data=val, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist4.history['loss'], color='teal', label='Training loss')\n",
    "plt.plot(hist4.history['val_loss'], color='orange', label='Validation loss')\n",
    "fig.suptitle('Inception-V3 Loss Values', fontsize=20)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Epoches')\n",
    "plt.ylabel('Losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist4.history['accuracy'], color='teal', label='Train Accuracy')\n",
    "plt.plot(hist4.history['val_accuracy'], color='orange', label='Validation Accuracy')\n",
    "fig.suptitle('Inception-V3 Accuracy Values', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = tf.zeros((5, 5), dtype=tf.int32)\n",
    "\n",
    "for batch in test.as_numpy_iterator():\n",
    "    X, y = batch\n",
    "    yhat = model4.predict(X)\n",
    "    y_pred = np.argmax(yhat, axis=1)\n",
    "    y_true = np.argmax(y, axis=1)\n",
    "    conf_mat += tf.math.confusion_matrix(y_true, y_pred, num_classes=5)\n",
    "\n",
    "class_names = ['Bathroom', 'Bedroom', 'Dining', 'Kitchen', 'Living Room']\n",
    "conf_mat_norm = np.around(conf_mat.numpy() / conf_mat.numpy().sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(conf_mat_norm, xticklabels=class_names, yticklabels=class_names, annot=True, fmt='.2f')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.save(os.path.join('models','InceptionV3-Classification.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss4, test_acc4= model4.evaluate(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All models graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last accuracy value for each model\n",
    "acc1 = hist1.history['val_accuracy'][-1]\n",
    "acc2 = hist2.history['val_accuracy'][-1]\n",
    "acc3 = hist3.history['val_accuracy'][-1]\n",
    "acc4 = hist4.history['val_accuracy'][-1]\n",
    "\n",
    "# Create a list of labels for the x-axis ticks\n",
    "labels = ['My Model', 'VGG-16', 'VGG-19', 'Inception-V3']\n",
    "\n",
    "# Set the position of the x-axis ticks\n",
    "x = [0, 1, 2, 3]\n",
    "\n",
    "# Create the bar graph\n",
    "fig, ax = plt.subplots()\n",
    "rects = ax.bar(x, [acc1, acc2, acc3, acc4], align='center', alpha=0.5)\n",
    "\n",
    "# Add labels, title, and grid\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Models Validation Accuracy Values')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.grid(axis='y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of labels for the x-axis ticks\n",
    "labels = ['My Model', 'VGG-16', 'VGG-19', 'Inception-V3']\n",
    "\n",
    "# Set the position of the x-axis ticks\n",
    "x = [0, 1, 2, 3]\n",
    "\n",
    "# Create the bar graph\n",
    "fig, ax = plt.subplots()\n",
    "rects = ax.bar(x, [test_acc1, test_acc2, test_acc3, test_acc4], align='center', alpha=0.5)\n",
    "\n",
    "# Add labels, title, and grid\n",
    "ax.set_ylabel('Test Accuracy')\n",
    "ax.set_title('Models Test Accuracy Values')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.grid(axis='y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('models/VGG16-Classification.h5')\n",
    "model2 = load_model('models/VGG19-Classification.h5')\n",
    "model3 = load_model('models/InceptionV3-Classification.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.evaluate(test)\n",
    "model2.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.evaluate(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FinalFYP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11395c6aec6451561c8b7dd6ff7c904ce2871c73bb0f9a03cceac25db9e36a4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
